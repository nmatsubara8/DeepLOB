{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.0 pytz-2023.3 tzdata-2023.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 07:40:28.161370: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 21 07:40:36 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.85.05    Driver Version: 528.24       CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 38%   36C    P8    17W / 215W |    844MiB /  8192MiB |      1%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A        20      G   /Xwayland                       N/A      |\r\n",
      "|    0   N/A  N/A        31      G   /Xwayland                       N/A      |\r\n",
      "|    0   N/A  N/A       361      G   /Xwayland                       N/A      |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import data:\n",
    "# 1. read the text file line by line;\n",
    "# 2. format the data in DataFrame.\n",
    "\n",
    "def read_data(path):\n",
    "    data_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            d_str = line.split()\n",
    "            d_tem = [float(d) for d in d_str]\n",
    "            data_list.append(d_tem)\n",
    "    data = pd.DataFrame(data_list)\n",
    "    return data.T\n",
    "\n",
    "# ready data for training:\n",
    "# 1. sample_size=100: the most 100 recent updates\n",
    "# 2. feature_num=40: 40 features per time stamp\n",
    "# 3. target_num=5: relative changes for the next 1,2,3,5 and 10 events(5 in total)\n",
    "def get_model_data(data, sample_size=100, feature_num=40, target_num=5):\n",
    "    data = data.values\n",
    "    shape = data.shape\n",
    "    X = np.zeros((shape[0]-sample_size, sample_size, feature_num))\n",
    "    Y = np.zeros(shape=(shape[0]-sample_size, target_num))\n",
    "    for i in range(shape[0]-sample_size):\n",
    "        X[i] = data[i:i+sample_size,0:feature_num]# take the first 40 columns as features\n",
    "        Y[i] = data[i+sample_size-1,-target_num:]# take the last 5 columns as labels\n",
    "    X = X.reshape(X.shape[0], sample_size, feature_num, 1)# add the 4th dimension: 1 channel\n",
    "    \n",
    "    # \"Benchmark dataset for mid-price forecasting of limit order book data with machine learning\"\n",
    "    # labels 1: equal to or greater than 0.002\n",
    "    # labels 2: -0.00199 to 0.00199\n",
    "    # labels 3: smaller or equal to -0.002\n",
    "    # Y=Y-1 relabels as 0,1,2\n",
    "    Y = Y-1\n",
    "    return X,Y\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_path = r'C:\\Users\\admin\\OneDrive\\ドキュメント\\Data\\BenchmarkDatasets\\BenchmarkDatasets\\NoAuction\\1.NoAuction_Zscore\\NoAuction_Zscore_Training\\Train_Dst_NoAuction_ZScore_CF_9.txt'\n",
    "data_path = r'./Train_Dst_NoAuction_ZScore_CF_9.txt'\n",
    "\n",
    "data = read_data(data_path)\n",
    "train_X, train_Y = get_model_data(data)\n",
    "train_Y = train_Y.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362300, 100, 40, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 07:44:40.900910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:44:40.905297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:44:40.905583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:44:40.906606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:44:40.906835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:44:40.907030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:45:17.756740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:45:17.757131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:45:17.757143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-21 07:45:17.757439: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-21 07:45:17.757470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5875 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 40, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 100, 20, 16)  48          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 100, 20, 16)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 100, 20, 16)  1040        ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 100, 20, 16)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 100, 20, 16)  1040        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 100, 20, 16)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 100, 10, 16)  528         ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 100, 10, 16)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 100, 10, 16)  1040        ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 100, 10, 16)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 100, 10, 16)  1040        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 100, 10, 16)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 100, 1, 16)   2576        ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 100, 1, 16)   0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 100, 1, 16)   1040        ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 100, 1, 16)   0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 100, 1, 16)   1040        ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 100, 1, 16)   0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 100, 1, 32)   544         ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 100, 1, 32)   544         ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 100, 1, 32)   0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 100, 1, 16)   0           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 100, 1, 32)   3104        ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 100, 1, 32)   5152        ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 100, 1, 32)   544         ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 100, 1, 96)   0           ['leaky_re_lu_10[0][0]',         \n",
      "                                                                  'leaky_re_lu_12[0][0]',         \n",
      "                                                                  'leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 100, 96)      0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           41216       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            195         ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 60,691\n",
      "Trainable params: 60,691\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 07:45:19.149077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-21 07:45:19.150785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-21 07:45:19.152371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# the size of a single input is (100,40)\n",
    "input_tensor = Input(shape=(100,40,1))\n",
    "\n",
    "# convolutional filter is (1,2) with stride of (1,2)\n",
    "layer_x = layers.Conv2D(16, (1,2), strides=(1,2))(input_tensor)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "layer_x = layers.Conv2D(16, (1,2), strides=(1,2))(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "layer_x = layers.Conv2D(16, (1,10))(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "# Inception Module\n",
    "tower_1 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\n",
    "tower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = layers.Conv2D(32, (3,1), padding='same')(tower_1)\n",
    "tower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n",
    "\n",
    "tower_2 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\n",
    "tower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = layers.Conv2D(32, (5,1), padding='same')(tower_2)\n",
    "tower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)  \n",
    "\n",
    "tower_3 = layers.MaxPooling2D((3,1), padding='same', strides=(1,1))(layer_x)\n",
    "tower_3 = layers.Conv2D(32, (1,1), padding='same')(tower_3)\n",
    "tower_3 = layers.LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "layer_x = layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "\n",
    "# concatenate features of tower_1, tower_2, tower_3\n",
    "layer_x = layers.Reshape((100,96))(layer_x)\n",
    "\n",
    "# 64 LSTM units\n",
    "layer_x = LSTM(64)(layer_x)\n",
    "# The last output layer uses a softmax activation function\n",
    "output = layers.Dense(3, activation='softmax')(layer_x)\n",
    "model = Model(input_tensor, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 07:45:35.000605: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5796800000 exceeds 10% of free system memory.\n",
      "2023-04-21 07:45:56.315904: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5796800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 07:45:58.709353: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-21 07:45:58.711067: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-21 07:45:58.712782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-21 07:45:59.870180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-21 07:45:59.873232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-21 07:45:59.875112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-21 07:46:01.716020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-21 07:46:04.131645: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa56c00da00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-21 07:46:04.131684: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 SUPER, Compute Capability 7.5\n",
      "2023-04-21 07:46:04.135980: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-21 07:46:04.240747: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11322/11322 [==============================] - 214s 18ms/step - loss: 0.8770 - accuracy: 0.6424\n",
      "Epoch 2/100\n",
      "11322/11322 [==============================] - 196s 17ms/step - loss: 0.7353 - accuracy: 0.6836\n",
      "Epoch 3/100\n",
      "11322/11322 [==============================] - 200s 18ms/step - loss: 0.6726 - accuracy: 0.7086\n",
      "Epoch 4/100\n",
      "11322/11322 [==============================] - 195s 17ms/step - loss: 0.6469 - accuracy: 0.7355\n",
      "Epoch 5/100\n",
      "11322/11322 [==============================] - 195s 17ms/step - loss: 0.5973 - accuracy: 0.7691\n",
      "Epoch 6/100\n",
      "11322/11322 [==============================] - 197s 17ms/step - loss: 0.5823 - accuracy: 0.7761\n",
      "Epoch 7/100\n",
      "11322/11322 [==============================] - 196s 17ms/step - loss: 0.5727 - accuracy: 0.7801\n",
      "Epoch 8/100\n",
      "11322/11322 [==============================] - 196s 17ms/step - loss: 0.5654 - accuracy: 0.7822\n",
      "Epoch 9/100\n",
      "11322/11322 [==============================] - 197s 17ms/step - loss: 0.5583 - accuracy: 0.7858\n",
      "Epoch 10/100\n",
      "  628/11322 [>.............................] - ETA: 3:06 - loss: 0.5602 - accuracy: 0.7863"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01, epsilon=1)# learning rate and epsilon are the same as paper DeepLOB\n",
    "y = to_categorical(train_Y[:,0])# y is the next event's mid price (k=1)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(train_X, y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.to_csv('FI2010_test.csv')\n",
    "data.to_csv('FI2010_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_path = r'E:\\JupyterFile\\BenchmarkDatasets\\BenchmarkDatasets\\NoAuction\\1.NoAuction_Zscore\\NoAuction_Zscore_Testing\\Test_Dst_NoAuction_ZScore_CF_9.txt'\n",
    "test_path = r'./Test_Dst_NoAuction_ZScore_CF_9.txt'\n",
    "test_data = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = read_data(test_path)\n",
    "test_X, test_Y = get_model_data(test_data)\n",
    "test_Y = test_Y.astype(int)\n",
    "test_y = to_categorical(test_Y[:,0])\n",
    "\n",
    "model.evaluate(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
